<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How to produce and consume events on Kafka with Spring Stream | CODE FARM</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="How to produce and consume events on Kafka with Spring Stream" />
<meta property="og:locale" content="en" />
<meta name="description" content="How to produce and consume events on Kafka with Spring Stream? What’s the bindings and binder? What’s the default binder meaning? What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. How does the produce function work? I mean how it is triggered to send messages? What if we want to send a message manually, like when we receive a user login event on a Rest Controller? What if there are multiple functions, but used to be handle diff topics? How to compiste functions to handle a topic? How does the composite functions to be bound to a destination? How to produce and consume events on Kafka with Spring Stream? How to produce and consume events on Kafka with Spring Stream? Apache Kafka is a highly popular option for data streaming. Spring Cloud Stream is a framework built upon Spring Boot for building message-driven microservice applications and it provides built-in capabilities to work with Apache Kafka as the underlying message broker. Here’s a basic guide on how to produce and consume events on Kafka using Spring Cloud Stream: Set Up Kafka: First you need to have a working Kafka instance. You can either install it on your machine or run it in a docker container. Create Spring Boot Application: You can create a Spring Boot application using Spring Initializr. Add Required Dependencies: You need to have the following dependencies in your pom.xml or build.gradle file. For Maven: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; For Gradle: dependencies { implementation &#39;org.springframework.cloud:spring-cloud-starter-stream-kafka&#39; implementation &#39;org.springframework.cloud:spring-cloud-stream&#39; } Configure the Application: In application.properties or application.yml file you need to set the Kafka broker address, the name of the topic, and other parameters if necessary. spring: cloud: stream: bindings: output: destination: topic-name binder: kafka kafka: binder: brokers: localhost:9092 Create a Source: A source is a channel through which the data flows out to the Kafka broker. Annotate an output channel with @Output. public interface ProducerBinding { String OUTPUT = &quot;output&quot;; @Output(OUTPUT) MessageChannel output(); } Publish Messages: Inject the source in your service, create a message and send it using output().send(MessageBuilder.withPayload(yourMessage).build()). @Autowired private ProducerBinding source; public void publish(String message){ source.output().send(MessageBuilder.withPayload(message).build()); } Create a Sink: A sink is a channel through which the data flows into the application from Kafka. Annotate an input channel with @Input. public interface ConsumerBinding { String INPUT = &quot;input&quot;; @Input(INPUT) SubscribableChannel input(); } Consume Messages: Create a consumer class where you listen to the messages. Annotate a method with @StreamListener to receive messages. @Service public class ConsumerService { @StreamListener(ConsumerBinding.INPUT) public void handle(String value) { // Process the message System.out.println(&quot;Received: &quot; + value); } } Run the Application: Now, you can run your Spring Boot application. It should be able to send and receive the messages from Kafka. Remember, this is just a basic guide that covers the core concepts. There are more configurations and details that you can explore as per your use case. Make sure to refer to the official documentations for both Spring Cloud Stream and Apache Kafka. What’s the bindings and binder? What’s the bindings and binder? Both “bindings” and “binder” are terms used within the Spring Cloud Stream (SCS) framework, and they’re central to understanding how Spring Cloud Stream operates. Bindings: In Spring Cloud Stream, a binding is a bridge between your application’s message channels and the message broker (like Apache Kafka or RabbitMQ). They form the core abstraction in Spring Cloud Stream programming model. The concept of ‘binding’ is about connecting your application with the messaging system via a Message Channel (a key abstraction in Spring Integration, where ‘input’ or ‘output’ represent an inbound or outbound entity). This wiring is auto-created by Spring Cloud Stream. In simple terms, SCS provides connectivity between your application and messaging middleware, and this connectivity is facilitated by ‘bindings’. For example, if you define a binding named “output” as in the previous example, Spring Cloud Stream will know that a channel named “output” should be used to dispatch the messages to the messaging middleware. Binder: The Binder is the component of Spring Cloud Stream responsible for providing the necessary configuration and implementation for the connection to the messaging system. Binders exist for various message brokers, including but not limited to RabbitMQ, Apache Kafka, Amazon Kinesis, etc. The binder brings the bits that are needed to connect the application to the specific message broker and acts as an adapter layer between your application and the messaging system. When Spring Cloud Stream receives a message that needs to be published, it’s the binder which takes care of how to connect to the broker, how to serialize the message, where to publish it (topics, routing key, etc.), and so on. It also deals with how to read and convert incoming messages before sending them to your application. Through this system of bindings and binders, Spring Cloud Stream abstracts away the specifics of the underlying message brokers, allowing developers to focus on writing the business logic. ’’’ The application.yml file is a configuration file used by Spring Boot applications. It’s a space-sensitive file in YAML format that Spring Boot reads at launch to configure properties of the application. In the example you referenced: spring: cloud: stream: bindings: output: destination: topic-name binder: kafka kafka: binder: brokers: localhost:9092 Here’s the explanation for this: spring: This is the root configuration prefix for all Spring Boot applications. cloud: This is the specific configuration prefix for all Spring Cloud applications. stream: This is the specific configuration prefix from the Spring Cloud Stream project. It’s used to configure the Spring Cloud Stream properties. bindings: These are the definitions of your input and output channels. In your case, you’re defining an output channel. output: This is the name of your output channel. It corresponds to the OUTPUT constant value (‘output’) defined in your code. destination: This is the name of the Kafka topic where the events will be produced. Messages sent to the ‘output’ channel will end up in this topic on the Kafka broker. binder: This defines the binder configuration that this binding should be created from. This is optional and if not present, the default binder configuration will be used. kafka: This is for Kafka-specific configuration. binder: It holds properties for kafka binder. brokers: This is the hostname and port for your Kafka broker(s). The application will connect to Kafka using these details. Remember that YAML files are whitespace and indentation sensitive. Misalignment may lead to an error or properties may not be assigned correctly. What’s the default binder meaning? What’s the default binder meaning? In Spring Cloud Stream, the binder is the piece that ties your application to the specific message broker (like RabbitMQ, Kafka, Google Pub-Sub, etc.). It does this by providing the necessary configuration and implementation of the broker-specific code. When you define the ‘binder’ property for a specific binding, you’re telling Spring Cloud Stream to use that as the binder (and hence the message broker) for that binding. However, when you don’t specify a ‘binder’ property for a binding, Spring Cloud Stream will use the ‘defaultBinder’ that’s defined in your application configurations. For example, consider a scenario where your application connects to two different message brokers - Kafka and RabbitMQ. In your configurations, you can define both Kafka and RabbitMQ binders, but also specify the Kafka binder as the ‘defaultBinder’. In the application.yaml file: spring: cloud: stream: defaultBinder: kafka kafka: binder: brokers: localhost:9092 rabbitmq: binder: address: localhost ... Any binding definitions that don’t explicitly set the ‘binder’ attribute will automatically use the Kafka binder because that’s defined as the ‘defaultBinder’. However, if you want a particular channel to use RabbitMQ instead, you can achieve that by explicitly stating so in the ‘binder’ attribute for that specific channel. spring: cloud: stream: bindings: myOutputChannel: destination: mytopic myRabbitChannel: destination: myqueue binder: rabbitmq In this example, myOutputChannel will use Kafka as the binder (as Kafka is defined as the default binder), and myRabbitChannel will use the RabbitMQ as the binder (as it’s explicitly defined for this binding). What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? No, if you only have one binder (like Kafka) in your application, you don’t need to specify it as the ‘defaultBinder’ explicitly. Spring Cloud Stream will automatically use the only available binder for your application. If you have only one binder configuration in your classpath, then Spring Cloud Stream smartly understands that to be the default binder for your application. Here is an example configuration where no default binder is specified, and there is only one binder, Kafka: spring: cloud: stream: kafka: binder: brokers: localhost:9092 bindings: output: destination: topic-name In this case, spring.cloud.stream.kafka.binder.brokers property maps to the Kafka broker, and spring.cloud.stream.bindings.output.destination specifies the name of the topic on the Kafka broker from which the messages will be published to. Your application will use Kafka as the binder since it’s the only binder available in the setup, and you don’t need to specify it as a default binder explicitly. The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. You’re correct. The Spring Cloud Stream framework has moved toward a more functional programming model, using java.util.function’s Supplier, Consumer, and Function for message handling. This is especially recommended for Spring Cloud Stream 3.0 and above. Here’s a quick sketch of how to use them with your Apache Kafka setup: Producer: Firstly, define a Supplier bean for producing a message: @Bean public Supplier&lt;String&gt; produce() { return () -&gt; { // generate message content String message = &quot;Hello, Kafka!&quot;; return message; }; } In your application.yml configure the output stream for the Supplier: spring: cloud: function: definition: produce stream: bindings: produce-out-0: destination: topic-name kafka: binder: brokers: localhost:9092 Consumer: Next, declare a Consumer to consume messages from a broker: @Bean public Consumer&lt;String&gt; consume() { return message -&gt; { // process message content System.out.println(&quot;Received: &quot; + message); }; } In your application.yml, configure the input stream for the Consumer: spring: cloud: function: definition: consume stream: bindings: consume-in-0: destination: topic-name kafka: binder: brokers: localhost:9092 By convention, SCS uses function names as the binding names: ‘produce-out-0’ and ‘consume-in-0’. ‘0’ is the index in case you have multiple inputs or outputs. But you can change these via Spring Cloud Stream’s ‘spring.cloud.stream.function.bindings.*’ property. In the latest functional programming model, you don’t explicitly deal with message channels or use annotations such as @Input or @Output. The methods signature implies whether the application is intended to be used for source/sink/processor. Remember, these examples are just basic scenarios and more complicated scenarios like content-type negotiation or error handling in Apache Kafka with Spring Cloud Stream may need additional steps. How does the produce function work? I mean how it is triggered to send messages? How does the produce function work? I mean how it is triggered to send messages? Great question! The Supplier function in Spring Cloud Stream is used to produce or generate messages that need to be sent to the message broker system, like Apache Kafka or RabbitMQ. However, a Supplier in Spring Cloud Stream is not called or triggered directly. Instead, the framework does it automatically for you at regular intervals. This interval is by default set at 1 message/second, but it can be easily configured using the property spring.cloud.stream.poller.fixed-delay. Here’s an example of how to adjust the poller’s interval: spring: cloud: stream: poller: fixed-delay: 5000 This configuration will trigger the Supplier function approximately every 5 seconds (value is in milliseconds) to generate a new message. Moreover, when the application starts up, Spring Cloud Stream automatically sets up a background loop that calls the Supplier.get() method at the specified rate (or the default rate, if no rate is specified) and sends its output to the specified message broker destination. Note: The Supplier function is generally used in source applications where you are producing messages and not consuming any. What if we want to send a message manually, like when we receive a user login event on a Rest Controller? What if we want to send a message manually, like when we receive a user login event on a Rest Controller? Indeed, the Supplier function is automatically triggered at regular intervals which is not an ideal scenario when you want to produce a message based on a certain event - like a user login event, as in your example. In such a case, you typically use a MessageChannel to manually send messages. However, with the functional programming model, you could use a StreamBridge. The StreamBridge is a utility that is automatically available in the context which you can Autowire and use it anywhere in your application to dynamically send messages to a destination. Here’s an example of how to use StreamBridge: @RestController public class LoginController { private final StreamBridge streamBridge; @Autowired public LoginController(StreamBridge streamBridge) { this.streamBridge = streamBridge; } @PostMapping(&quot;/login&quot;) public String loginUser(@RequestBody User user) { // validate and login user, generate response // ... // send a message when a user logs in streamBridge.send(&quot;produce-out-0&quot;, user); return &quot;Login Successful!&quot;; } } In this example, each time the “/login” endpoint is hit, a User object would be sent to the output channel “produce-out-0”. Remember to configure the output binding in your application.yml appropriately: spring: cloud: stream: bindings: produce-out-0: destination: topic-name kafka: binder: brokers: localhost:9092 The StreamBridge utility provides a flexible way to produce messages from anywhere within your application, making it a great choice when you need to manually send messages in a Spring Cloud Stream application. What if there are multiple functions, but used to be handle diff topics? What if there are multiple functions, but used to be handle diff topics? If you have multiple functions corresponding to different topics (destinations), you can easily configure them in Spring Cloud Stream. Each java.util.function.Function, java.util.function.Consumer or java.util.function.Supplier bean can correspond to a different binder destination. Here’s an example: Producer Function Beans: @Bean public Supplier&lt;String&gt; produceUserEvent() { return () -&gt; { // generate user event message content String message = &quot;User event&quot;; return message; }; } @Bean public Supplier&lt;String&gt; produceProductEvent() { return () -&gt; { // generate product event message content String message = &quot;Product event&quot;; return message; }; } Consumer Function Beans: @Bean public Consumer&lt;String&gt; consumeUserEvent() { return message -&gt; { // process user event message content System.out.println(&quot;Received user event: &quot; + message); }; } @Bean public Consumer&lt;String&gt; consumeProductEvent() { return message -&gt; { // process product event message content System.out.println(&quot;Received product event: &quot; + message); }; } Configuration in application.yml: You can declare the bindings and specific destinations in your application.yml: spring: cloud: function: definition: produceUserEvent;consumeUserEvent;produceProductEvent;consumeProductEvent stream: bindings: produceUserEvent-out-0: destination: user-events consumeUserEvent-in-0: destination: user-events produceProductEvent-out-0: destination: product-events consumeProductEvent-in-0: destination: product-events kafka: binder: brokers: localhost:9092 In this example, produceUserEvent-out-0 and consumeUserEvent-in-0 are used to produce and consume messages for “user events”, while produceProductEvent-out-0 and consumeProductEvent-in-0 are used to produce and consume “product events”. Each -out-0 or -in-0 suffix represents the output or input channel binding for that function. In the end, each function serves its own topic, producing or consuming different set of data, while having separate responsibility. got it, it seems that the function.definition is used to tell the SCS to indentify the handlers? q That’s correct. The spring.cloud.function.definition property in the application configuration can be used to specify the beans - either Supplier, Consumer, or Function - that Spring Cloud Stream should bind to messaging channels. If you have multiple function beans in your Spring application context, but you only want to use some of them for messaging purposes, this is where spring.cloud.function.definition becomes handy. The property takes a semi-colon separated list of the bean names to be bound to the messaging system. For example: spring: cloud: function: definition: myFunction;myConsumer;mySupplier In this example, myFunction, myConsumer, mySupplier are the names of Function, Consumer, Supplier beans respectively. Spring Cloud Stream will bind only these beans to messaging channels according to the output/input bindings specified elsewhere in your properties. It’s important to remember that the function definition should have the same name as the function bean in the application. If your function bean is defined as follows: @Bean public Consumer&lt;String&gt; myConsumer() { return data -&gt; { /*...*/ }; } You should use myConsumer in the spring.cloud.function.definition. How to compiste functions to handle a topic? How to compiste functions to handle a topic? Composing functions is a powerful feature of Spring Cloud Stream that allows multiple operations to be performed on a message in a sequence. You can chain multiple functions together to process the input data. To compose functions, you use the pipe symbol |, similar to how you would in a Unix/Linux command line. Here’s an example: @Bean public Function&lt;String, String&gt; firstFunction() { return input -&gt; input.toUpperCase(); } @Bean public Function&lt;String, String&gt; secondFunction() { return input -&gt; &quot;Message: &quot; + input; } And in your application configuration file: spring: cloud: function: definition: firstFunction|secondFunction The firstFunction will be applied first, and then its output will be used as the input to the secondFunction. This way, when a message comes in, it’ll be first converted to uppercase by firstFunction, and then secondFunction will prepended “Message: “ to it. Keep in mind, when composing functions: Each function must “match” with its neighbouring function - the output type of one function should be the same as the input type of the next. Create separate Application Configuration file (application.yml or application.properties) for each binder (input or output) when using the composed function. The binding destination should match for both producer and consumer otherwise producer will not be able to send and the consumer won’t consume the messages. Composing two or more consumers (Consumer&lt;A&gt; | Consumer&lt;B&gt;) or two or more suppliers (Supplier&lt;A&gt; | Supplier&lt;B&gt;) is not valid as per Spring Cloud Stream documentation because the supplier does not consume any input, and the consumer does not produce any output. If message types do not match, a converter can be used to typecast them. How does the composite functions to be bound to a destination? How does the composite functions to be bound to a destination? The composed (composite) functions can be bound to a destination (topic) through the application configuration file (like application.yml) in Spring Cloud Stream. The basic procedure is to define the destination in the spring.cloud.stream.bindings.&lt;functionName&gt;-in-0.destination for input bindings and spring.cloud.stream.bindings.&lt;functionName&gt;-out-0.destination for output bindings, where &lt;functionName&gt; is the composed function name. For example, consider two functions: uppercase and prefix which you have composed as processFunction: @Bean public Function&lt;String, String&gt; uppercase() { return String::toUpperCase; } @Bean public Function&lt;String, String&gt; prefix() { return input -&gt; &quot;Hello &quot; + input; } You define the composite function in your spring.cloud.function.definition like this: spring: cloud: function: definition: processFunction To bind the composite function to a topic, define the input and output bindings: spring: cloud: stream: bindings: processFunction-in-0: destination: input-topic processFunction-out-0: destination: output-topic In this setup, messages coming in from input-topic will trigger the composite function processFunction (which consists of uppercase and prefix) and the results will be sent to output-topic. Remember, the bindings property should match the function name. So if your composed function is called processFunction, you should have your bindings as processFunction-in-0 and processFunction-out-0. I didn’t see any configuration about the realtion between processFunction and the uppercase and prefix. I apologize for the confusion, I should have clarified that in the explanation. The processFunction was intended as a placeholder name in the bindings configuration for the composed function (uppercase prefix). The binding happens based on the spring.cloud.function.definition property. The composed function is defined as the concatenation of the beans you want to compose (uppercase prefix, in this case) in the spring.cloud.function.definition property. Here’s how you can specify uppercase and prefix functions and bind them to input and output channels: @Bean public Function&lt;String, String&gt; uppercase() { return String::toUpperCase; } @Bean public Function&lt;String, String&gt; prefix() { return input -&gt; &quot;Hello &quot; + input; } In your application.yml, you compose them together: spring: cloud: function: definition: uppercase|prefix cloud: stream: bindings: uppercase|prefix-in-0: destination: input-topic uppercase|prefix-out-0: destination: output-topic In this setup, when a message comes in from the input-topic, it is first processed by the uppercase function, and then it’s output is processed by the prefix function, and then the final output is sent to output-topic. The use of | (pipe) character enables function composition, where the output of one function becomes the input of the next one in line." />
<meta property="og:description" content="How to produce and consume events on Kafka with Spring Stream? What’s the bindings and binder? What’s the default binder meaning? What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. How does the produce function work? I mean how it is triggered to send messages? What if we want to send a message manually, like when we receive a user login event on a Rest Controller? What if there are multiple functions, but used to be handle diff topics? How to compiste functions to handle a topic? How does the composite functions to be bound to a destination? How to produce and consume events on Kafka with Spring Stream? How to produce and consume events on Kafka with Spring Stream? Apache Kafka is a highly popular option for data streaming. Spring Cloud Stream is a framework built upon Spring Boot for building message-driven microservice applications and it provides built-in capabilities to work with Apache Kafka as the underlying message broker. Here’s a basic guide on how to produce and consume events on Kafka using Spring Cloud Stream: Set Up Kafka: First you need to have a working Kafka instance. You can either install it on your machine or run it in a docker container. Create Spring Boot Application: You can create a Spring Boot application using Spring Initializr. Add Required Dependencies: You need to have the following dependencies in your pom.xml or build.gradle file. For Maven: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; For Gradle: dependencies { implementation &#39;org.springframework.cloud:spring-cloud-starter-stream-kafka&#39; implementation &#39;org.springframework.cloud:spring-cloud-stream&#39; } Configure the Application: In application.properties or application.yml file you need to set the Kafka broker address, the name of the topic, and other parameters if necessary. spring: cloud: stream: bindings: output: destination: topic-name binder: kafka kafka: binder: brokers: localhost:9092 Create a Source: A source is a channel through which the data flows out to the Kafka broker. Annotate an output channel with @Output. public interface ProducerBinding { String OUTPUT = &quot;output&quot;; @Output(OUTPUT) MessageChannel output(); } Publish Messages: Inject the source in your service, create a message and send it using output().send(MessageBuilder.withPayload(yourMessage).build()). @Autowired private ProducerBinding source; public void publish(String message){ source.output().send(MessageBuilder.withPayload(message).build()); } Create a Sink: A sink is a channel through which the data flows into the application from Kafka. Annotate an input channel with @Input. public interface ConsumerBinding { String INPUT = &quot;input&quot;; @Input(INPUT) SubscribableChannel input(); } Consume Messages: Create a consumer class where you listen to the messages. Annotate a method with @StreamListener to receive messages. @Service public class ConsumerService { @StreamListener(ConsumerBinding.INPUT) public void handle(String value) { // Process the message System.out.println(&quot;Received: &quot; + value); } } Run the Application: Now, you can run your Spring Boot application. It should be able to send and receive the messages from Kafka. Remember, this is just a basic guide that covers the core concepts. There are more configurations and details that you can explore as per your use case. Make sure to refer to the official documentations for both Spring Cloud Stream and Apache Kafka. What’s the bindings and binder? What’s the bindings and binder? Both “bindings” and “binder” are terms used within the Spring Cloud Stream (SCS) framework, and they’re central to understanding how Spring Cloud Stream operates. Bindings: In Spring Cloud Stream, a binding is a bridge between your application’s message channels and the message broker (like Apache Kafka or RabbitMQ). They form the core abstraction in Spring Cloud Stream programming model. The concept of ‘binding’ is about connecting your application with the messaging system via a Message Channel (a key abstraction in Spring Integration, where ‘input’ or ‘output’ represent an inbound or outbound entity). This wiring is auto-created by Spring Cloud Stream. In simple terms, SCS provides connectivity between your application and messaging middleware, and this connectivity is facilitated by ‘bindings’. For example, if you define a binding named “output” as in the previous example, Spring Cloud Stream will know that a channel named “output” should be used to dispatch the messages to the messaging middleware. Binder: The Binder is the component of Spring Cloud Stream responsible for providing the necessary configuration and implementation for the connection to the messaging system. Binders exist for various message brokers, including but not limited to RabbitMQ, Apache Kafka, Amazon Kinesis, etc. The binder brings the bits that are needed to connect the application to the specific message broker and acts as an adapter layer between your application and the messaging system. When Spring Cloud Stream receives a message that needs to be published, it’s the binder which takes care of how to connect to the broker, how to serialize the message, where to publish it (topics, routing key, etc.), and so on. It also deals with how to read and convert incoming messages before sending them to your application. Through this system of bindings and binders, Spring Cloud Stream abstracts away the specifics of the underlying message brokers, allowing developers to focus on writing the business logic. ’’’ The application.yml file is a configuration file used by Spring Boot applications. It’s a space-sensitive file in YAML format that Spring Boot reads at launch to configure properties of the application. In the example you referenced: spring: cloud: stream: bindings: output: destination: topic-name binder: kafka kafka: binder: brokers: localhost:9092 Here’s the explanation for this: spring: This is the root configuration prefix for all Spring Boot applications. cloud: This is the specific configuration prefix for all Spring Cloud applications. stream: This is the specific configuration prefix from the Spring Cloud Stream project. It’s used to configure the Spring Cloud Stream properties. bindings: These are the definitions of your input and output channels. In your case, you’re defining an output channel. output: This is the name of your output channel. It corresponds to the OUTPUT constant value (‘output’) defined in your code. destination: This is the name of the Kafka topic where the events will be produced. Messages sent to the ‘output’ channel will end up in this topic on the Kafka broker. binder: This defines the binder configuration that this binding should be created from. This is optional and if not present, the default binder configuration will be used. kafka: This is for Kafka-specific configuration. binder: It holds properties for kafka binder. brokers: This is the hostname and port for your Kafka broker(s). The application will connect to Kafka using these details. Remember that YAML files are whitespace and indentation sensitive. Misalignment may lead to an error or properties may not be assigned correctly. What’s the default binder meaning? What’s the default binder meaning? In Spring Cloud Stream, the binder is the piece that ties your application to the specific message broker (like RabbitMQ, Kafka, Google Pub-Sub, etc.). It does this by providing the necessary configuration and implementation of the broker-specific code. When you define the ‘binder’ property for a specific binding, you’re telling Spring Cloud Stream to use that as the binder (and hence the message broker) for that binding. However, when you don’t specify a ‘binder’ property for a binding, Spring Cloud Stream will use the ‘defaultBinder’ that’s defined in your application configurations. For example, consider a scenario where your application connects to two different message brokers - Kafka and RabbitMQ. In your configurations, you can define both Kafka and RabbitMQ binders, but also specify the Kafka binder as the ‘defaultBinder’. In the application.yaml file: spring: cloud: stream: defaultBinder: kafka kafka: binder: brokers: localhost:9092 rabbitmq: binder: address: localhost ... Any binding definitions that don’t explicitly set the ‘binder’ attribute will automatically use the Kafka binder because that’s defined as the ‘defaultBinder’. However, if you want a particular channel to use RabbitMQ instead, you can achieve that by explicitly stating so in the ‘binder’ attribute for that specific channel. spring: cloud: stream: bindings: myOutputChannel: destination: mytopic myRabbitChannel: destination: myqueue binder: rabbitmq In this example, myOutputChannel will use Kafka as the binder (as Kafka is defined as the default binder), and myRabbitChannel will use the RabbitMQ as the binder (as it’s explicitly defined for this binding). What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? No, if you only have one binder (like Kafka) in your application, you don’t need to specify it as the ‘defaultBinder’ explicitly. Spring Cloud Stream will automatically use the only available binder for your application. If you have only one binder configuration in your classpath, then Spring Cloud Stream smartly understands that to be the default binder for your application. Here is an example configuration where no default binder is specified, and there is only one binder, Kafka: spring: cloud: stream: kafka: binder: brokers: localhost:9092 bindings: output: destination: topic-name In this case, spring.cloud.stream.kafka.binder.brokers property maps to the Kafka broker, and spring.cloud.stream.bindings.output.destination specifies the name of the topic on the Kafka broker from which the messages will be published to. Your application will use Kafka as the binder since it’s the only binder available in the setup, and you don’t need to specify it as a default binder explicitly. The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. You’re correct. The Spring Cloud Stream framework has moved toward a more functional programming model, using java.util.function’s Supplier, Consumer, and Function for message handling. This is especially recommended for Spring Cloud Stream 3.0 and above. Here’s a quick sketch of how to use them with your Apache Kafka setup: Producer: Firstly, define a Supplier bean for producing a message: @Bean public Supplier&lt;String&gt; produce() { return () -&gt; { // generate message content String message = &quot;Hello, Kafka!&quot;; return message; }; } In your application.yml configure the output stream for the Supplier: spring: cloud: function: definition: produce stream: bindings: produce-out-0: destination: topic-name kafka: binder: brokers: localhost:9092 Consumer: Next, declare a Consumer to consume messages from a broker: @Bean public Consumer&lt;String&gt; consume() { return message -&gt; { // process message content System.out.println(&quot;Received: &quot; + message); }; } In your application.yml, configure the input stream for the Consumer: spring: cloud: function: definition: consume stream: bindings: consume-in-0: destination: topic-name kafka: binder: brokers: localhost:9092 By convention, SCS uses function names as the binding names: ‘produce-out-0’ and ‘consume-in-0’. ‘0’ is the index in case you have multiple inputs or outputs. But you can change these via Spring Cloud Stream’s ‘spring.cloud.stream.function.bindings.*’ property. In the latest functional programming model, you don’t explicitly deal with message channels or use annotations such as @Input or @Output. The methods signature implies whether the application is intended to be used for source/sink/processor. Remember, these examples are just basic scenarios and more complicated scenarios like content-type negotiation or error handling in Apache Kafka with Spring Cloud Stream may need additional steps. How does the produce function work? I mean how it is triggered to send messages? How does the produce function work? I mean how it is triggered to send messages? Great question! The Supplier function in Spring Cloud Stream is used to produce or generate messages that need to be sent to the message broker system, like Apache Kafka or RabbitMQ. However, a Supplier in Spring Cloud Stream is not called or triggered directly. Instead, the framework does it automatically for you at regular intervals. This interval is by default set at 1 message/second, but it can be easily configured using the property spring.cloud.stream.poller.fixed-delay. Here’s an example of how to adjust the poller’s interval: spring: cloud: stream: poller: fixed-delay: 5000 This configuration will trigger the Supplier function approximately every 5 seconds (value is in milliseconds) to generate a new message. Moreover, when the application starts up, Spring Cloud Stream automatically sets up a background loop that calls the Supplier.get() method at the specified rate (or the default rate, if no rate is specified) and sends its output to the specified message broker destination. Note: The Supplier function is generally used in source applications where you are producing messages and not consuming any. What if we want to send a message manually, like when we receive a user login event on a Rest Controller? What if we want to send a message manually, like when we receive a user login event on a Rest Controller? Indeed, the Supplier function is automatically triggered at regular intervals which is not an ideal scenario when you want to produce a message based on a certain event - like a user login event, as in your example. In such a case, you typically use a MessageChannel to manually send messages. However, with the functional programming model, you could use a StreamBridge. The StreamBridge is a utility that is automatically available in the context which you can Autowire and use it anywhere in your application to dynamically send messages to a destination. Here’s an example of how to use StreamBridge: @RestController public class LoginController { private final StreamBridge streamBridge; @Autowired public LoginController(StreamBridge streamBridge) { this.streamBridge = streamBridge; } @PostMapping(&quot;/login&quot;) public String loginUser(@RequestBody User user) { // validate and login user, generate response // ... // send a message when a user logs in streamBridge.send(&quot;produce-out-0&quot;, user); return &quot;Login Successful!&quot;; } } In this example, each time the “/login” endpoint is hit, a User object would be sent to the output channel “produce-out-0”. Remember to configure the output binding in your application.yml appropriately: spring: cloud: stream: bindings: produce-out-0: destination: topic-name kafka: binder: brokers: localhost:9092 The StreamBridge utility provides a flexible way to produce messages from anywhere within your application, making it a great choice when you need to manually send messages in a Spring Cloud Stream application. What if there are multiple functions, but used to be handle diff topics? What if there are multiple functions, but used to be handle diff topics? If you have multiple functions corresponding to different topics (destinations), you can easily configure them in Spring Cloud Stream. Each java.util.function.Function, java.util.function.Consumer or java.util.function.Supplier bean can correspond to a different binder destination. Here’s an example: Producer Function Beans: @Bean public Supplier&lt;String&gt; produceUserEvent() { return () -&gt; { // generate user event message content String message = &quot;User event&quot;; return message; }; } @Bean public Supplier&lt;String&gt; produceProductEvent() { return () -&gt; { // generate product event message content String message = &quot;Product event&quot;; return message; }; } Consumer Function Beans: @Bean public Consumer&lt;String&gt; consumeUserEvent() { return message -&gt; { // process user event message content System.out.println(&quot;Received user event: &quot; + message); }; } @Bean public Consumer&lt;String&gt; consumeProductEvent() { return message -&gt; { // process product event message content System.out.println(&quot;Received product event: &quot; + message); }; } Configuration in application.yml: You can declare the bindings and specific destinations in your application.yml: spring: cloud: function: definition: produceUserEvent;consumeUserEvent;produceProductEvent;consumeProductEvent stream: bindings: produceUserEvent-out-0: destination: user-events consumeUserEvent-in-0: destination: user-events produceProductEvent-out-0: destination: product-events consumeProductEvent-in-0: destination: product-events kafka: binder: brokers: localhost:9092 In this example, produceUserEvent-out-0 and consumeUserEvent-in-0 are used to produce and consume messages for “user events”, while produceProductEvent-out-0 and consumeProductEvent-in-0 are used to produce and consume “product events”. Each -out-0 or -in-0 suffix represents the output or input channel binding for that function. In the end, each function serves its own topic, producing or consuming different set of data, while having separate responsibility. got it, it seems that the function.definition is used to tell the SCS to indentify the handlers? q That’s correct. The spring.cloud.function.definition property in the application configuration can be used to specify the beans - either Supplier, Consumer, or Function - that Spring Cloud Stream should bind to messaging channels. If you have multiple function beans in your Spring application context, but you only want to use some of them for messaging purposes, this is where spring.cloud.function.definition becomes handy. The property takes a semi-colon separated list of the bean names to be bound to the messaging system. For example: spring: cloud: function: definition: myFunction;myConsumer;mySupplier In this example, myFunction, myConsumer, mySupplier are the names of Function, Consumer, Supplier beans respectively. Spring Cloud Stream will bind only these beans to messaging channels according to the output/input bindings specified elsewhere in your properties. It’s important to remember that the function definition should have the same name as the function bean in the application. If your function bean is defined as follows: @Bean public Consumer&lt;String&gt; myConsumer() { return data -&gt; { /*...*/ }; } You should use myConsumer in the spring.cloud.function.definition. How to compiste functions to handle a topic? How to compiste functions to handle a topic? Composing functions is a powerful feature of Spring Cloud Stream that allows multiple operations to be performed on a message in a sequence. You can chain multiple functions together to process the input data. To compose functions, you use the pipe symbol |, similar to how you would in a Unix/Linux command line. Here’s an example: @Bean public Function&lt;String, String&gt; firstFunction() { return input -&gt; input.toUpperCase(); } @Bean public Function&lt;String, String&gt; secondFunction() { return input -&gt; &quot;Message: &quot; + input; } And in your application configuration file: spring: cloud: function: definition: firstFunction|secondFunction The firstFunction will be applied first, and then its output will be used as the input to the secondFunction. This way, when a message comes in, it’ll be first converted to uppercase by firstFunction, and then secondFunction will prepended “Message: “ to it. Keep in mind, when composing functions: Each function must “match” with its neighbouring function - the output type of one function should be the same as the input type of the next. Create separate Application Configuration file (application.yml or application.properties) for each binder (input or output) when using the composed function. The binding destination should match for both producer and consumer otherwise producer will not be able to send and the consumer won’t consume the messages. Composing two or more consumers (Consumer&lt;A&gt; | Consumer&lt;B&gt;) or two or more suppliers (Supplier&lt;A&gt; | Supplier&lt;B&gt;) is not valid as per Spring Cloud Stream documentation because the supplier does not consume any input, and the consumer does not produce any output. If message types do not match, a converter can be used to typecast them. How does the composite functions to be bound to a destination? How does the composite functions to be bound to a destination? The composed (composite) functions can be bound to a destination (topic) through the application configuration file (like application.yml) in Spring Cloud Stream. The basic procedure is to define the destination in the spring.cloud.stream.bindings.&lt;functionName&gt;-in-0.destination for input bindings and spring.cloud.stream.bindings.&lt;functionName&gt;-out-0.destination for output bindings, where &lt;functionName&gt; is the composed function name. For example, consider two functions: uppercase and prefix which you have composed as processFunction: @Bean public Function&lt;String, String&gt; uppercase() { return String::toUpperCase; } @Bean public Function&lt;String, String&gt; prefix() { return input -&gt; &quot;Hello &quot; + input; } You define the composite function in your spring.cloud.function.definition like this: spring: cloud: function: definition: processFunction To bind the composite function to a topic, define the input and output bindings: spring: cloud: stream: bindings: processFunction-in-0: destination: input-topic processFunction-out-0: destination: output-topic In this setup, messages coming in from input-topic will trigger the composite function processFunction (which consists of uppercase and prefix) and the results will be sent to output-topic. Remember, the bindings property should match the function name. So if your composed function is called processFunction, you should have your bindings as processFunction-in-0 and processFunction-out-0. I didn’t see any configuration about the realtion between processFunction and the uppercase and prefix. I apologize for the confusion, I should have clarified that in the explanation. The processFunction was intended as a placeholder name in the bindings configuration for the composed function (uppercase prefix). The binding happens based on the spring.cloud.function.definition property. The composed function is defined as the concatenation of the beans you want to compose (uppercase prefix, in this case) in the spring.cloud.function.definition property. Here’s how you can specify uppercase and prefix functions and bind them to input and output channels: @Bean public Function&lt;String, String&gt; uppercase() { return String::toUpperCase; } @Bean public Function&lt;String, String&gt; prefix() { return input -&gt; &quot;Hello &quot; + input; } In your application.yml, you compose them together: spring: cloud: function: definition: uppercase|prefix cloud: stream: bindings: uppercase|prefix-in-0: destination: input-topic uppercase|prefix-out-0: destination: output-topic In this setup, when a message comes in from the input-topic, it is first processed by the uppercase function, and then it’s output is processed by the prefix function, and then the final output is sent to output-topic. The use of | (pipe) character enables function composition, where the output of one function becomes the input of the next one in line." />
<link rel="canonical" href="https://blog.codefarm.me/2024/01/06/what-is-about-spring-cloud-stream/" />
<meta property="og:url" content="https://blog.codefarm.me/2024/01/06/what-is-about-spring-cloud-stream/" />
<meta property="og:site_name" content="CODE FARM" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-06T17:37:25+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How to produce and consume events on Kafka with Spring Stream" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-01-06T17:37:25+08:00","datePublished":"2024-01-06T17:37:25+08:00","description":"How to produce and consume events on Kafka with Spring Stream? What’s the bindings and binder? What’s the default binder meaning? What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. How does the produce function work? I mean how it is triggered to send messages? What if we want to send a message manually, like when we receive a user login event on a Rest Controller? What if there are multiple functions, but used to be handle diff topics? How to compiste functions to handle a topic? How does the composite functions to be bound to a destination? How to produce and consume events on Kafka with Spring Stream? How to produce and consume events on Kafka with Spring Stream? Apache Kafka is a highly popular option for data streaming. Spring Cloud Stream is a framework built upon Spring Boot for building message-driven microservice applications and it provides built-in capabilities to work with Apache Kafka as the underlying message broker. Here’s a basic guide on how to produce and consume events on Kafka using Spring Cloud Stream: Set Up Kafka: First you need to have a working Kafka instance. You can either install it on your machine or run it in a docker container. Create Spring Boot Application: You can create a Spring Boot application using Spring Initializr. Add Required Dependencies: You need to have the following dependencies in your pom.xml or build.gradle file. For Maven: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; For Gradle: dependencies { implementation &#39;org.springframework.cloud:spring-cloud-starter-stream-kafka&#39; implementation &#39;org.springframework.cloud:spring-cloud-stream&#39; } Configure the Application: In application.properties or application.yml file you need to set the Kafka broker address, the name of the topic, and other parameters if necessary. spring: cloud: stream: bindings: output: destination: topic-name binder: kafka kafka: binder: brokers: localhost:9092 Create a Source: A source is a channel through which the data flows out to the Kafka broker. Annotate an output channel with @Output. public interface ProducerBinding { String OUTPUT = &quot;output&quot;; @Output(OUTPUT) MessageChannel output(); } Publish Messages: Inject the source in your service, create a message and send it using output().send(MessageBuilder.withPayload(yourMessage).build()). @Autowired private ProducerBinding source; public void publish(String message){ source.output().send(MessageBuilder.withPayload(message).build()); } Create a Sink: A sink is a channel through which the data flows into the application from Kafka. Annotate an input channel with @Input. public interface ConsumerBinding { String INPUT = &quot;input&quot;; @Input(INPUT) SubscribableChannel input(); } Consume Messages: Create a consumer class where you listen to the messages. Annotate a method with @StreamListener to receive messages. @Service public class ConsumerService { @StreamListener(ConsumerBinding.INPUT) public void handle(String value) { // Process the message System.out.println(&quot;Received: &quot; + value); } } Run the Application: Now, you can run your Spring Boot application. It should be able to send and receive the messages from Kafka. Remember, this is just a basic guide that covers the core concepts. There are more configurations and details that you can explore as per your use case. Make sure to refer to the official documentations for both Spring Cloud Stream and Apache Kafka. What’s the bindings and binder? What’s the bindings and binder? Both “bindings” and “binder” are terms used within the Spring Cloud Stream (SCS) framework, and they’re central to understanding how Spring Cloud Stream operates. Bindings: In Spring Cloud Stream, a binding is a bridge between your application’s message channels and the message broker (like Apache Kafka or RabbitMQ). They form the core abstraction in Spring Cloud Stream programming model. The concept of ‘binding’ is about connecting your application with the messaging system via a Message Channel (a key abstraction in Spring Integration, where ‘input’ or ‘output’ represent an inbound or outbound entity). This wiring is auto-created by Spring Cloud Stream. In simple terms, SCS provides connectivity between your application and messaging middleware, and this connectivity is facilitated by ‘bindings’. For example, if you define a binding named “output” as in the previous example, Spring Cloud Stream will know that a channel named “output” should be used to dispatch the messages to the messaging middleware. Binder: The Binder is the component of Spring Cloud Stream responsible for providing the necessary configuration and implementation for the connection to the messaging system. Binders exist for various message brokers, including but not limited to RabbitMQ, Apache Kafka, Amazon Kinesis, etc. The binder brings the bits that are needed to connect the application to the specific message broker and acts as an adapter layer between your application and the messaging system. When Spring Cloud Stream receives a message that needs to be published, it’s the binder which takes care of how to connect to the broker, how to serialize the message, where to publish it (topics, routing key, etc.), and so on. It also deals with how to read and convert incoming messages before sending them to your application. Through this system of bindings and binders, Spring Cloud Stream abstracts away the specifics of the underlying message brokers, allowing developers to focus on writing the business logic. ’’’ The application.yml file is a configuration file used by Spring Boot applications. It’s a space-sensitive file in YAML format that Spring Boot reads at launch to configure properties of the application. In the example you referenced: spring: cloud: stream: bindings: output: destination: topic-name binder: kafka kafka: binder: brokers: localhost:9092 Here’s the explanation for this: spring: This is the root configuration prefix for all Spring Boot applications. cloud: This is the specific configuration prefix for all Spring Cloud applications. stream: This is the specific configuration prefix from the Spring Cloud Stream project. It’s used to configure the Spring Cloud Stream properties. bindings: These are the definitions of your input and output channels. In your case, you’re defining an output channel. output: This is the name of your output channel. It corresponds to the OUTPUT constant value (‘output’) defined in your code. destination: This is the name of the Kafka topic where the events will be produced. Messages sent to the ‘output’ channel will end up in this topic on the Kafka broker. binder: This defines the binder configuration that this binding should be created from. This is optional and if not present, the default binder configuration will be used. kafka: This is for Kafka-specific configuration. binder: It holds properties for kafka binder. brokers: This is the hostname and port for your Kafka broker(s). The application will connect to Kafka using these details. Remember that YAML files are whitespace and indentation sensitive. Misalignment may lead to an error or properties may not be assigned correctly. What’s the default binder meaning? What’s the default binder meaning? In Spring Cloud Stream, the binder is the piece that ties your application to the specific message broker (like RabbitMQ, Kafka, Google Pub-Sub, etc.). It does this by providing the necessary configuration and implementation of the broker-specific code. When you define the ‘binder’ property for a specific binding, you’re telling Spring Cloud Stream to use that as the binder (and hence the message broker) for that binding. However, when you don’t specify a ‘binder’ property for a binding, Spring Cloud Stream will use the ‘defaultBinder’ that’s defined in your application configurations. For example, consider a scenario where your application connects to two different message brokers - Kafka and RabbitMQ. In your configurations, you can define both Kafka and RabbitMQ binders, but also specify the Kafka binder as the ‘defaultBinder’. In the application.yaml file: spring: cloud: stream: defaultBinder: kafka kafka: binder: brokers: localhost:9092 rabbitmq: binder: address: localhost ... Any binding definitions that don’t explicitly set the ‘binder’ attribute will automatically use the Kafka binder because that’s defined as the ‘defaultBinder’. However, if you want a particular channel to use RabbitMQ instead, you can achieve that by explicitly stating so in the ‘binder’ attribute for that specific channel. spring: cloud: stream: bindings: myOutputChannel: destination: mytopic myRabbitChannel: destination: myqueue binder: rabbitmq In this example, myOutputChannel will use Kafka as the binder (as Kafka is defined as the default binder), and myRabbitChannel will use the RabbitMQ as the binder (as it’s explicitly defined for this binding). What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly? No, if you only have one binder (like Kafka) in your application, you don’t need to specify it as the ‘defaultBinder’ explicitly. Spring Cloud Stream will automatically use the only available binder for your application. If you have only one binder configuration in your classpath, then Spring Cloud Stream smartly understands that to be the default binder for your application. Here is an example configuration where no default binder is specified, and there is only one binder, Kafka: spring: cloud: stream: kafka: binder: brokers: localhost:9092 bindings: output: destination: topic-name In this case, spring.cloud.stream.kafka.binder.brokers property maps to the Kafka broker, and spring.cloud.stream.bindings.output.destination specifies the name of the topic on the Kafka broker from which the messages will be published to. Your application will use Kafka as the binder since it’s the only binder available in the setup, and you don’t need to specify it as a default binder explicitly. The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc. You’re correct. The Spring Cloud Stream framework has moved toward a more functional programming model, using java.util.function’s Supplier, Consumer, and Function for message handling. This is especially recommended for Spring Cloud Stream 3.0 and above. Here’s a quick sketch of how to use them with your Apache Kafka setup: Producer: Firstly, define a Supplier bean for producing a message: @Bean public Supplier&lt;String&gt; produce() { return () -&gt; { // generate message content String message = &quot;Hello, Kafka!&quot;; return message; }; } In your application.yml configure the output stream for the Supplier: spring: cloud: function: definition: produce stream: bindings: produce-out-0: destination: topic-name kafka: binder: brokers: localhost:9092 Consumer: Next, declare a Consumer to consume messages from a broker: @Bean public Consumer&lt;String&gt; consume() { return message -&gt; { // process message content System.out.println(&quot;Received: &quot; + message); }; } In your application.yml, configure the input stream for the Consumer: spring: cloud: function: definition: consume stream: bindings: consume-in-0: destination: topic-name kafka: binder: brokers: localhost:9092 By convention, SCS uses function names as the binding names: ‘produce-out-0’ and ‘consume-in-0’. ‘0’ is the index in case you have multiple inputs or outputs. But you can change these via Spring Cloud Stream’s ‘spring.cloud.stream.function.bindings.*’ property. In the latest functional programming model, you don’t explicitly deal with message channels or use annotations such as @Input or @Output. The methods signature implies whether the application is intended to be used for source/sink/processor. Remember, these examples are just basic scenarios and more complicated scenarios like content-type negotiation or error handling in Apache Kafka with Spring Cloud Stream may need additional steps. How does the produce function work? I mean how it is triggered to send messages? How does the produce function work? I mean how it is triggered to send messages? Great question! The Supplier function in Spring Cloud Stream is used to produce or generate messages that need to be sent to the message broker system, like Apache Kafka or RabbitMQ. However, a Supplier in Spring Cloud Stream is not called or triggered directly. Instead, the framework does it automatically for you at regular intervals. This interval is by default set at 1 message/second, but it can be easily configured using the property spring.cloud.stream.poller.fixed-delay. Here’s an example of how to adjust the poller’s interval: spring: cloud: stream: poller: fixed-delay: 5000 This configuration will trigger the Supplier function approximately every 5 seconds (value is in milliseconds) to generate a new message. Moreover, when the application starts up, Spring Cloud Stream automatically sets up a background loop that calls the Supplier.get() method at the specified rate (or the default rate, if no rate is specified) and sends its output to the specified message broker destination. Note: The Supplier function is generally used in source applications where you are producing messages and not consuming any. What if we want to send a message manually, like when we receive a user login event on a Rest Controller? What if we want to send a message manually, like when we receive a user login event on a Rest Controller? Indeed, the Supplier function is automatically triggered at regular intervals which is not an ideal scenario when you want to produce a message based on a certain event - like a user login event, as in your example. In such a case, you typically use a MessageChannel to manually send messages. However, with the functional programming model, you could use a StreamBridge. The StreamBridge is a utility that is automatically available in the context which you can Autowire and use it anywhere in your application to dynamically send messages to a destination. Here’s an example of how to use StreamBridge: @RestController public class LoginController { private final StreamBridge streamBridge; @Autowired public LoginController(StreamBridge streamBridge) { this.streamBridge = streamBridge; } @PostMapping(&quot;/login&quot;) public String loginUser(@RequestBody User user) { // validate and login user, generate response // ... // send a message when a user logs in streamBridge.send(&quot;produce-out-0&quot;, user); return &quot;Login Successful!&quot;; } } In this example, each time the “/login” endpoint is hit, a User object would be sent to the output channel “produce-out-0”. Remember to configure the output binding in your application.yml appropriately: spring: cloud: stream: bindings: produce-out-0: destination: topic-name kafka: binder: brokers: localhost:9092 The StreamBridge utility provides a flexible way to produce messages from anywhere within your application, making it a great choice when you need to manually send messages in a Spring Cloud Stream application. What if there are multiple functions, but used to be handle diff topics? What if there are multiple functions, but used to be handle diff topics? If you have multiple functions corresponding to different topics (destinations), you can easily configure them in Spring Cloud Stream. Each java.util.function.Function, java.util.function.Consumer or java.util.function.Supplier bean can correspond to a different binder destination. Here’s an example: Producer Function Beans: @Bean public Supplier&lt;String&gt; produceUserEvent() { return () -&gt; { // generate user event message content String message = &quot;User event&quot;; return message; }; } @Bean public Supplier&lt;String&gt; produceProductEvent() { return () -&gt; { // generate product event message content String message = &quot;Product event&quot;; return message; }; } Consumer Function Beans: @Bean public Consumer&lt;String&gt; consumeUserEvent() { return message -&gt; { // process user event message content System.out.println(&quot;Received user event: &quot; + message); }; } @Bean public Consumer&lt;String&gt; consumeProductEvent() { return message -&gt; { // process product event message content System.out.println(&quot;Received product event: &quot; + message); }; } Configuration in application.yml: You can declare the bindings and specific destinations in your application.yml: spring: cloud: function: definition: produceUserEvent;consumeUserEvent;produceProductEvent;consumeProductEvent stream: bindings: produceUserEvent-out-0: destination: user-events consumeUserEvent-in-0: destination: user-events produceProductEvent-out-0: destination: product-events consumeProductEvent-in-0: destination: product-events kafka: binder: brokers: localhost:9092 In this example, produceUserEvent-out-0 and consumeUserEvent-in-0 are used to produce and consume messages for “user events”, while produceProductEvent-out-0 and consumeProductEvent-in-0 are used to produce and consume “product events”. Each -out-0 or -in-0 suffix represents the output or input channel binding for that function. In the end, each function serves its own topic, producing or consuming different set of data, while having separate responsibility. got it, it seems that the function.definition is used to tell the SCS to indentify the handlers? q That’s correct. The spring.cloud.function.definition property in the application configuration can be used to specify the beans - either Supplier, Consumer, or Function - that Spring Cloud Stream should bind to messaging channels. If you have multiple function beans in your Spring application context, but you only want to use some of them for messaging purposes, this is where spring.cloud.function.definition becomes handy. The property takes a semi-colon separated list of the bean names to be bound to the messaging system. For example: spring: cloud: function: definition: myFunction;myConsumer;mySupplier In this example, myFunction, myConsumer, mySupplier are the names of Function, Consumer, Supplier beans respectively. Spring Cloud Stream will bind only these beans to messaging channels according to the output/input bindings specified elsewhere in your properties. It’s important to remember that the function definition should have the same name as the function bean in the application. If your function bean is defined as follows: @Bean public Consumer&lt;String&gt; myConsumer() { return data -&gt; { /*...*/ }; } You should use myConsumer in the spring.cloud.function.definition. How to compiste functions to handle a topic? How to compiste functions to handle a topic? Composing functions is a powerful feature of Spring Cloud Stream that allows multiple operations to be performed on a message in a sequence. You can chain multiple functions together to process the input data. To compose functions, you use the pipe symbol |, similar to how you would in a Unix/Linux command line. Here’s an example: @Bean public Function&lt;String, String&gt; firstFunction() { return input -&gt; input.toUpperCase(); } @Bean public Function&lt;String, String&gt; secondFunction() { return input -&gt; &quot;Message: &quot; + input; } And in your application configuration file: spring: cloud: function: definition: firstFunction|secondFunction The firstFunction will be applied first, and then its output will be used as the input to the secondFunction. This way, when a message comes in, it’ll be first converted to uppercase by firstFunction, and then secondFunction will prepended “Message: “ to it. Keep in mind, when composing functions: Each function must “match” with its neighbouring function - the output type of one function should be the same as the input type of the next. Create separate Application Configuration file (application.yml or application.properties) for each binder (input or output) when using the composed function. The binding destination should match for both producer and consumer otherwise producer will not be able to send and the consumer won’t consume the messages. Composing two or more consumers (Consumer&lt;A&gt; | Consumer&lt;B&gt;) or two or more suppliers (Supplier&lt;A&gt; | Supplier&lt;B&gt;) is not valid as per Spring Cloud Stream documentation because the supplier does not consume any input, and the consumer does not produce any output. If message types do not match, a converter can be used to typecast them. How does the composite functions to be bound to a destination? How does the composite functions to be bound to a destination? The composed (composite) functions can be bound to a destination (topic) through the application configuration file (like application.yml) in Spring Cloud Stream. The basic procedure is to define the destination in the spring.cloud.stream.bindings.&lt;functionName&gt;-in-0.destination for input bindings and spring.cloud.stream.bindings.&lt;functionName&gt;-out-0.destination for output bindings, where &lt;functionName&gt; is the composed function name. For example, consider two functions: uppercase and prefix which you have composed as processFunction: @Bean public Function&lt;String, String&gt; uppercase() { return String::toUpperCase; } @Bean public Function&lt;String, String&gt; prefix() { return input -&gt; &quot;Hello &quot; + input; } You define the composite function in your spring.cloud.function.definition like this: spring: cloud: function: definition: processFunction To bind the composite function to a topic, define the input and output bindings: spring: cloud: stream: bindings: processFunction-in-0: destination: input-topic processFunction-out-0: destination: output-topic In this setup, messages coming in from input-topic will trigger the composite function processFunction (which consists of uppercase and prefix) and the results will be sent to output-topic. Remember, the bindings property should match the function name. So if your composed function is called processFunction, you should have your bindings as processFunction-in-0 and processFunction-out-0. I didn’t see any configuration about the realtion between processFunction and the uppercase and prefix. I apologize for the confusion, I should have clarified that in the explanation. The processFunction was intended as a placeholder name in the bindings configuration for the composed function (uppercase prefix). The binding happens based on the spring.cloud.function.definition property. The composed function is defined as the concatenation of the beans you want to compose (uppercase prefix, in this case) in the spring.cloud.function.definition property. Here’s how you can specify uppercase and prefix functions and bind them to input and output channels: @Bean public Function&lt;String, String&gt; uppercase() { return String::toUpperCase; } @Bean public Function&lt;String, String&gt; prefix() { return input -&gt; &quot;Hello &quot; + input; } In your application.yml, you compose them together: spring: cloud: function: definition: uppercase|prefix cloud: stream: bindings: uppercase|prefix-in-0: destination: input-topic uppercase|prefix-out-0: destination: output-topic In this setup, when a message comes in from the input-topic, it is first processed by the uppercase function, and then it’s output is processed by the prefix function, and then the final output is sent to output-topic. The use of | (pipe) character enables function composition, where the output of one function becomes the input of the next one in line.","headline":"How to produce and consume events on Kafka with Spring Stream","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.codefarm.me/2024/01/06/what-is-about-spring-cloud-stream/"},"url":"https://blog.codefarm.me/2024/01/06/what-is-about-spring-cloud-stream/"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <link rel="stylesheet" href="/assets/css/style.css"><!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-SN88FJ18E5"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-SN88FJ18E5');
    </script></head>
  <body>
    <header class="c-header">
  <div class="o-container">
    <a class="c-header-title" href="/">CODE FARM</a>
    <button class="c-header-nav-toggle" id="nav-toggle" aria-label="Toggle navigation">
      <span class="c-header-nav-toggle-icon"></span>
    </button>
    <div class="c-header-nav-wrapper" id="nav-wrapper">
      <nav class="c-header-nav">
        <a href="/">Home</a>
        <a href="/categories/">Category</a>
        <a href="/tags/">Tag</a>
        <a href="/archives/">Archive</a>
        <a href="/about/">About</a>
        <a href="https://resume.github.io/?looogos" target="_blank">R&eacute;sum&eacute;</a>
      </nav>
    </div>
  </div>
  



<div class="o-container">
  <div class="c-banner">
    <img src="/assets/images/galaxy.svg" alt="Galaxy background" class="c-banner-bg">
    <div class="c-banner-quote">
      <p>"The Renaissance was a time when art, science, and philosophy flourished."</p>
      <cite>- Michelangelo</cite>
    </div>
  </div>
</div>
</header>

    <main class="o-container">
      <article class="c-post">
  <header class="c-post-header">
    <h1 class="c-post-title">How to produce and consume events on Kafka with Spring Stream</h1><p class="c-post-meta">06 Jan 2024</p>
  </header>

  <div class="c-post-content">
    <ul id="markdown-toc">
  <li><a href="#how-to-produce-and-consume-events-on-kafka-with-spring-stream" id="markdown-toc-how-to-produce-and-consume-events-on-kafka-with-spring-stream">How to produce and consume events on Kafka with Spring Stream?</a></li>
  <li><a href="#whats-the-bindings-and-binder" id="markdown-toc-whats-the-bindings-and-binder">What’s the bindings and binder?</a></li>
  <li><a href="#whats-the-default-binder-meaning" id="markdown-toc-whats-the-default-binder-meaning">What’s the default binder meaning?</a></li>
  <li><a href="#what-if-there-is-only-ond-binder-like-kafka-should-we-need-to-specify-the-defaultbinder-explicitly" id="markdown-toc-what-if-there-is-only-ond-binder-like-kafka-should-we-need-to-specify-the-defaultbinder-explicitly">What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly?</a></li>
  <li><a href="#the-sample-code-you-used-by-messagechannel-etc-nowdays-scs-will-use-the-spring-cloud-functions-like-supplier-consumer-etc" id="markdown-toc-the-sample-code-you-used-by-messagechannel-etc-nowdays-scs-will-use-the-spring-cloud-functions-like-supplier-consumer-etc">The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc.</a></li>
  <li><a href="#how-does-the-produce-function-work-i-mean-how-it-is-triggered-to-send-messages" id="markdown-toc-how-does-the-produce-function-work-i-mean-how-it-is-triggered-to-send-messages">How does the produce function work? I mean how it is triggered to send messages?</a></li>
  <li><a href="#what-if-we-want-to-send-a-message-manually-like-when-we-receive-a-user-login-event-on-a-rest-controller" id="markdown-toc-what-if-we-want-to-send-a-message-manually-like-when-we-receive-a-user-login-event-on-a-rest-controller">What if we want to send a message manually, like when we receive a user login event on a Rest Controller?</a></li>
  <li><a href="#what-if-there-are-multiple-functions-but-used-to-be-handle-diff-topics" id="markdown-toc-what-if-there-are-multiple-functions-but-used-to-be-handle-diff-topics">What if there are multiple functions, but used to be handle diff topics?</a></li>
  <li><a href="#how-to-compiste-functions-to-handle-a-topic" id="markdown-toc-how-to-compiste-functions-to-handle-a-topic">How to compiste functions to handle a topic?</a></li>
  <li><a href="#how-does-the-composite-functions-to-be-bound-to-a-destination" id="markdown-toc-how-does-the-composite-functions-to-be-bound-to-a-destination">How does the composite functions to be bound to a destination?</a></li>
</ul>

<h2 id="how-to-produce-and-consume-events-on-kafka-with-spring-stream">How to produce and consume events on Kafka with Spring Stream?</h2>

<blockquote>
  <p>How to produce and consume events on Kafka with Spring Stream?</p>
</blockquote>

<p>Apache Kafka is a highly popular option for data streaming. Spring Cloud Stream is a framework built upon Spring Boot for building message-driven microservice applications and it provides built-in capabilities to work with Apache Kafka as the underlying message broker.</p>

<p>Here’s a basic guide on how to produce and consume events on Kafka using Spring Cloud Stream:</p>

<ol>
  <li>
    <p><strong>Set Up Kafka:</strong>
First you need to have a working Kafka instance. You can either install it on your machine or run it in a docker container.</p>
  </li>
  <li>
    <p><strong>Create Spring Boot Application:</strong>
You can create a Spring Boot application using Spring Initializr.</p>
  </li>
  <li>
    <p><strong>Add Required Dependencies:</strong>
You need to have the following dependencies in your <code class="language-plaintext highlighter-rouge">pom.xml</code> or <code class="language-plaintext highlighter-rouge">build.gradle</code> file.</p>

    <p>For Maven:</p>
    <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;dependencies&gt;</span>
     <span class="nt">&lt;dependency&gt;</span>
         <span class="nt">&lt;groupId&gt;</span>org.springframework.cloud<span class="nt">&lt;/groupId&gt;</span>
         <span class="nt">&lt;artifactId&gt;</span>spring-cloud-starter-stream-kafka<span class="nt">&lt;/artifactId&gt;</span>
     <span class="nt">&lt;/dependency&gt;</span>
     <span class="nt">&lt;dependency&gt;</span>
         <span class="nt">&lt;groupId&gt;</span>org.springframework.cloud<span class="nt">&lt;/groupId&gt;</span>
         <span class="nt">&lt;artifactId&gt;</span>spring-cloud-stream<span class="nt">&lt;/artifactId&gt;</span>
     <span class="nt">&lt;/dependency&gt;</span>
 <span class="nt">&lt;/dependencies&gt;</span>
</code></pre></div>    </div>

    <p>For Gradle:</p>
    <div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">dependencies</span> <span class="o">{</span>
     <span class="n">implementation</span> <span class="s1">'org.springframework.cloud:spring-cloud-starter-stream-kafka'</span>
     <span class="n">implementation</span> <span class="s1">'org.springframework.cloud:spring-cloud-stream'</span>
 <span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Configure the Application:</strong>
In <code class="language-plaintext highlighter-rouge">application.properties</code> or <code class="language-plaintext highlighter-rouge">application.yml</code> file you need to set the Kafka broker address, the name of the topic, and other parameters if necessary.</p>

    <div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="na">spring</span><span class="pi">:</span>
   <span class="na">cloud</span><span class="pi">:</span>
     <span class="na">stream</span><span class="pi">:</span>
       <span class="na">bindings</span><span class="pi">:</span>
         <span class="na">output</span><span class="pi">:</span>
           <span class="na">destination</span><span class="pi">:</span> <span class="s">topic-name</span>
           <span class="na">binder</span><span class="pi">:</span> <span class="s">kafka</span>
       <span class="na">kafka</span><span class="pi">:</span>
         <span class="na">binder</span><span class="pi">:</span>
           <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Create a Source:</strong>
A source is a channel through which the data flows out to the Kafka broker. Annotate an output channel with <code class="language-plaintext highlighter-rouge">@Output</code>.</p>

    <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="kd">public</span> <span class="kd">interface</span> <span class="nc">ProducerBinding</span> <span class="o">{</span>

     <span class="nc">String</span> <span class="no">OUTPUT</span> <span class="o">=</span> <span class="s">"output"</span><span class="o">;</span>

     <span class="nd">@Output</span><span class="o">(</span><span class="no">OUTPUT</span><span class="o">)</span>
     <span class="nc">MessageChannel</span> <span class="nf">output</span><span class="o">();</span>

 <span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Publish Messages:</strong>
Inject the source in your service, create a message and send it using <code class="language-plaintext highlighter-rouge">output().send(MessageBuilder.withPayload(yourMessage).build())</code>.</p>

    <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nd">@Autowired</span>
 <span class="kd">private</span> <span class="nc">ProducerBinding</span> <span class="n">source</span><span class="o">;</span>

 <span class="kd">public</span> <span class="kt">void</span> <span class="nf">publish</span><span class="o">(</span><span class="nc">String</span> <span class="n">message</span><span class="o">){</span>
     <span class="n">source</span><span class="o">.</span><span class="na">output</span><span class="o">().</span><span class="na">send</span><span class="o">(</span><span class="nc">MessageBuilder</span><span class="o">.</span><span class="na">withPayload</span><span class="o">(</span><span class="n">message</span><span class="o">).</span><span class="na">build</span><span class="o">());</span>
 <span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Create a Sink:</strong>
A sink is a channel through which the data flows into the application from Kafka. Annotate an input channel with <code class="language-plaintext highlighter-rouge">@Input</code>.</p>

    <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="kd">public</span> <span class="kd">interface</span> <span class="nc">ConsumerBinding</span> <span class="o">{</span>

     <span class="nc">String</span> <span class="no">INPUT</span> <span class="o">=</span> <span class="s">"input"</span><span class="o">;</span>

     <span class="nd">@Input</span><span class="o">(</span><span class="no">INPUT</span><span class="o">)</span>
     <span class="nc">SubscribableChannel</span> <span class="nf">input</span><span class="o">();</span>

 <span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Consume Messages:</strong>
Create a consumer class where you listen to the messages. Annotate a method with <code class="language-plaintext highlighter-rouge">@StreamListener</code> to receive messages.</p>

    <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nd">@Service</span>
 <span class="kd">public</span> <span class="kd">class</span> <span class="nc">ConsumerService</span> <span class="o">{</span>

     <span class="nd">@StreamListener</span><span class="o">(</span><span class="nc">ConsumerBinding</span><span class="o">.</span><span class="na">INPUT</span><span class="o">)</span>
     <span class="kd">public</span> <span class="kt">void</span> <span class="nf">handle</span><span class="o">(</span><span class="nc">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Process the message</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Received: "</span> <span class="o">+</span> <span class="n">value</span><span class="o">);</span>
     <span class="o">}</span>
 <span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Run the Application:</strong>
Now, you can run your Spring Boot application. It should be able to send and receive the messages from Kafka.</p>
  </li>
</ol>

<p>Remember, this is just a basic guide that covers the core concepts. There are more configurations and details that you can explore as per your use case. Make sure to refer to the official documentations for both Spring Cloud Stream and Apache Kafka.</p>

<h2 id="whats-the-bindings-and-binder">What’s the bindings and binder?</h2>

<blockquote>
  <p>What’s the bindings and binder?</p>
</blockquote>

<p>Both “bindings” and “binder” are terms used within the Spring Cloud Stream (SCS) framework, and they’re central to understanding how Spring Cloud Stream operates.</p>

<ol>
  <li>
    <p><strong>Bindings</strong>: In Spring Cloud Stream, a binding is a bridge between your application’s message channels and the message broker (like Apache Kafka or RabbitMQ). They form the core abstraction in Spring Cloud Stream programming model.</p>

    <p>The concept of ‘binding’ is about connecting your application with the messaging system via a Message Channel (a key abstraction in Spring Integration, where ‘input’ or ‘output’ represent an inbound or outbound entity).</p>

    <p>This wiring is auto-created by Spring Cloud Stream. In simple terms, SCS provides connectivity between your application and messaging middleware, and this connectivity is facilitated by ‘bindings’.</p>

    <p>For example, if you define a binding named “output” as in the previous example, Spring Cloud Stream will know that a channel named “output” should be used to dispatch the messages to the messaging middleware.</p>
  </li>
  <li>
    <p><strong>Binder</strong>: The Binder is the component of Spring Cloud Stream responsible for providing the necessary configuration and implementation for the connection to the messaging system.</p>

    <p>Binders exist for various message brokers, including but not limited to RabbitMQ, Apache Kafka, Amazon Kinesis, etc. The binder brings the bits that are needed to connect the application to the specific message broker and acts as an adapter layer between your application and the messaging system.</p>

    <p>When Spring Cloud Stream receives a message that needs to be published, it’s the binder which takes care of how to connect to the broker, how to serialize the message, where to publish it (topics, routing key, etc.), and so on. It also deals with how to read and convert incoming messages before sending them to your application.</p>
  </li>
</ol>

<p>Through this system of bindings and binders, Spring Cloud Stream abstracts away the specifics of the underlying message brokers, allowing developers to focus on writing the business logic.</p>

<p>’’’</p>

<p>The application.yml file is a configuration file used by Spring Boot applications. It’s a space-sensitive file in YAML format that Spring Boot reads at launch to configure properties of the application.</p>

<p>In the example you referenced:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">output</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">topic-name</span>
          <span class="na">binder</span><span class="pi">:</span> <span class="s">kafka</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
</code></pre></div></div>

<p>Here’s the explanation for this:</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">spring</code>: This is the root configuration prefix for all Spring Boot applications.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">cloud</code>: This is the specific configuration prefix for all Spring Cloud applications.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">stream</code>: This is the specific configuration prefix from the Spring Cloud Stream project. It’s used to configure the Spring Cloud Stream properties.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">bindings</code>: These are the definitions of your input and output channels. In your case, you’re defining an output channel.</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">output</code>: This is the name of your output channel. It corresponds to the <code class="language-plaintext highlighter-rouge">OUTPUT</code> constant value (‘output’) defined in your code.</p>

        <ul>
          <li>
            <p><code class="language-plaintext highlighter-rouge">destination</code>: This is the name of the Kafka topic where the events will be produced. Messages sent to the ‘output’ channel will end up in this topic on the Kafka broker.</p>
          </li>
          <li>
            <p><code class="language-plaintext highlighter-rouge">binder</code>: This defines the binder configuration that this binding should be created from. This is optional and if not present, the default binder configuration will be used.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">kafka</code>: This is for Kafka-specific configuration.</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">binder</code>: It holds properties for kafka binder.</p>

        <ul>
          <li><code class="language-plaintext highlighter-rouge">brokers</code>: This is the hostname and port for your Kafka broker(s). The application will connect to Kafka using these details.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>Remember that YAML files are whitespace and indentation sensitive. Misalignment may lead to an error or properties may not be assigned correctly.</p>

<h2 id="whats-the-default-binder-meaning">What’s the default binder meaning?</h2>

<blockquote>
  <p>What’s the default binder meaning?</p>
</blockquote>

<p>In Spring Cloud Stream, the binder is the piece that ties your application to the specific message broker (like RabbitMQ, Kafka, Google Pub-Sub, etc.). It does this by providing the necessary configuration and implementation of the broker-specific code.</p>

<p>When you define the ‘binder’ property for a specific binding, you’re telling Spring Cloud Stream to use that as the binder (and hence the message broker) for that binding.</p>

<p>However, when you don’t specify a ‘binder’ property for a binding, Spring Cloud Stream will use the ‘defaultBinder’ that’s defined in your application configurations.</p>

<p>For example, consider a scenario where your application connects to two different message brokers - Kafka and RabbitMQ. In your configurations, you can define both Kafka and RabbitMQ binders, but also specify the Kafka binder as the ‘defaultBinder’.</p>

<p>In the <code class="language-plaintext highlighter-rouge">application.yaml</code> file:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">defaultBinder</span><span class="pi">:</span> <span class="s">kafka</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
      <span class="na">rabbitmq</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">address</span><span class="pi">:</span> <span class="s">localhost</span>
<span class="nn">...</span>
</code></pre></div></div>
<p>Any binding definitions that don’t explicitly set the ‘binder’ attribute will automatically use the Kafka binder because that’s defined as the ‘defaultBinder’. However, if you want a particular channel to use RabbitMQ instead, you can achieve that by explicitly stating so in the ‘binder’ attribute for that specific channel.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">myOutputChannel</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">mytopic</span>
        <span class="na">myRabbitChannel</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">myqueue</span>
          <span class="na">binder</span><span class="pi">:</span> <span class="s">rabbitmq</span>
</code></pre></div></div>
<p>In this example, <code class="language-plaintext highlighter-rouge">myOutputChannel</code> will use Kafka as the binder (as Kafka is defined as the default binder), and <code class="language-plaintext highlighter-rouge">myRabbitChannel</code> will use the RabbitMQ as the binder (as it’s explicitly defined for this binding).</p>

<h2 id="what-if-there-is-only-ond-binder-like-kafka-should-we-need-to-specify-the-defaultbinder-explicitly">What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly?</h2>

<blockquote>
  <p>What if there is only ond binder like Kafka? Should we need to specify the defaultBinder explicitly?</p>
</blockquote>

<p>No, if you only have one binder (like Kafka) in your application, you don’t need to specify it as the ‘defaultBinder’ explicitly.</p>

<p>Spring Cloud Stream will automatically use the only available binder for your application. If you have only one binder configuration in your classpath, then Spring Cloud Stream smartly understands that to be the default binder for your application.</p>

<p>Here is an example configuration where no default binder is specified, and there is only one binder, Kafka:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">output</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">topic-name</span>
</code></pre></div></div>

<p>In this case, <code class="language-plaintext highlighter-rouge">spring.cloud.stream.kafka.binder.brokers</code> property maps to the Kafka broker, and <code class="language-plaintext highlighter-rouge">spring.cloud.stream.bindings.output.destination</code> specifies the name of the topic on the Kafka broker from which the messages will be published to.</p>

<p>Your application will use Kafka as the binder since it’s the only binder available in the setup, and you don’t need to specify it as a default binder explicitly.</p>

<h2 id="the-sample-code-you-used-by-messagechannel-etc-nowdays-scs-will-use-the-spring-cloud-functions-like-supplier-consumer-etc">The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc.</h2>

<blockquote>
  <p>The sample code you used by MessageChannel etc, nowdays SCS will use the spring cloud functions like Supplier, Consumer etc.</p>
</blockquote>

<p>You’re correct. The Spring Cloud Stream framework has moved toward a more functional programming model, using <code class="language-plaintext highlighter-rouge">java.util.function</code>’s <code class="language-plaintext highlighter-rouge">Supplier</code>, <code class="language-plaintext highlighter-rouge">Consumer</code>, and <code class="language-plaintext highlighter-rouge">Function</code> for message handling. This is especially recommended for Spring Cloud Stream 3.0 and above. Here’s a quick sketch of how to use them with your Apache Kafka setup:</p>

<p><strong>Producer:</strong></p>

<p>Firstly, define a <code class="language-plaintext highlighter-rouge">Supplier</code> bean for producing a message:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Supplier</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">produce</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// generate message content</span>
        <span class="nc">String</span> <span class="n">message</span> <span class="o">=</span> <span class="s">"Hello, Kafka!"</span><span class="o">;</span>
        <span class="k">return</span> <span class="n">message</span><span class="o">;</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p>In your <code class="language-plaintext highlighter-rouge">application.yml</code> configure the output stream for the <code class="language-plaintext highlighter-rouge">Supplier</code>:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">produce</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">produce-out-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">topic-name</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
</code></pre></div></div>

<p><strong>Consumer:</strong></p>

<p>Next, declare a <code class="language-plaintext highlighter-rouge">Consumer</code> to consume messages from a broker:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Consumer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">consume</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// process message content</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Received: "</span> <span class="o">+</span> <span class="n">message</span><span class="o">);</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p>In your <code class="language-plaintext highlighter-rouge">application.yml</code>, configure the input stream for the <code class="language-plaintext highlighter-rouge">Consumer</code>:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">consume</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">consume-in-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">topic-name</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
</code></pre></div></div>

<p>By convention, SCS uses function names as the binding names: ‘produce-out-0’ and ‘consume-in-0’. ‘0’ is the index in case you have multiple inputs or outputs. But you can change these via Spring Cloud Stream’s ‘spring.cloud.stream.function.bindings.*’ property.</p>

<p>In the latest functional programming model, you don’t explicitly deal with message channels or use annotations such as <code class="language-plaintext highlighter-rouge">@Input</code> or <code class="language-plaintext highlighter-rouge">@Output</code>.
The methods signature implies whether the application is intended to be used for source/sink/processor.</p>

<p>Remember, these examples are just basic scenarios and more complicated scenarios like content-type negotiation or error handling in Apache Kafka with Spring Cloud Stream may need additional steps.</p>

<h2 id="how-does-the-produce-function-work-i-mean-how-it-is-triggered-to-send-messages">How does the produce function work? I mean how it is triggered to send messages?</h2>

<blockquote>
  <p>How does the produce function work? I mean how it is triggered to send messages?</p>
</blockquote>

<p>Great question! The Supplier function in Spring Cloud Stream is used to produce or generate messages that need to be sent to the message broker system, like Apache Kafka or RabbitMQ.</p>

<p>However, a <code class="language-plaintext highlighter-rouge">Supplier</code> in Spring Cloud Stream is not called or triggered directly. Instead, the framework does it automatically for you at regular intervals. This interval is by default set at 1 message/second, but it can be easily configured using the property <code class="language-plaintext highlighter-rouge">spring.cloud.stream.poller.fixed-delay</code>.</p>

<p>Here’s an example of how to adjust the poller’s interval:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">poller</span><span class="pi">:</span>
        <span class="na">fixed-delay</span><span class="pi">:</span> <span class="m">5000</span>
</code></pre></div></div>

<p>This configuration will trigger the <code class="language-plaintext highlighter-rouge">Supplier</code> function approximately every 5 seconds (value is in milliseconds) to generate a new message.</p>

<p>Moreover, when the application starts up, Spring Cloud Stream automatically sets up a background loop that calls the <code class="language-plaintext highlighter-rouge">Supplier.get()</code> method at the specified rate (or the default rate, if no rate is specified) and sends its output to the specified message broker destination.</p>

<p>Note: The Supplier function is generally used in source applications where you are producing messages and not consuming any.</p>

<h2 id="what-if-we-want-to-send-a-message-manually-like-when-we-receive-a-user-login-event-on-a-rest-controller">What if we want to send a message manually, like when we receive a user login event on a Rest Controller?</h2>

<blockquote>
  <p>What if we want to send a message manually, like when we receive a user login event on a Rest Controller?</p>
</blockquote>

<p>Indeed, the Supplier function is automatically triggered at regular intervals which is not an ideal scenario when you want to produce a message based on a certain event - like a user login event, as in your example.</p>

<p>In such a case, you typically use a <code class="language-plaintext highlighter-rouge">MessageChannel</code> to manually send messages. However, with the functional programming model, you could use a <code class="language-plaintext highlighter-rouge">StreamBridge</code>. The <code class="language-plaintext highlighter-rouge">StreamBridge</code> is a utility that is automatically available in the context which you can <code class="language-plaintext highlighter-rouge">Autowire</code> and use it anywhere in your application to dynamically send messages to a destination.</p>

<p>Here’s an example of how to use <code class="language-plaintext highlighter-rouge">StreamBridge</code>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@RestController</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">LoginController</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">StreamBridge</span> <span class="n">streamBridge</span><span class="o">;</span>

    <span class="nd">@Autowired</span>
    <span class="kd">public</span> <span class="nf">LoginController</span><span class="o">(</span><span class="nc">StreamBridge</span> <span class="n">streamBridge</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">streamBridge</span> <span class="o">=</span> <span class="n">streamBridge</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@PostMapping</span><span class="o">(</span><span class="s">"/login"</span><span class="o">)</span>
    <span class="kd">public</span> <span class="nc">String</span> <span class="nf">loginUser</span><span class="o">(</span><span class="nd">@RequestBody</span> <span class="nc">User</span> <span class="n">user</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// validate and login user, generate response</span>
        <span class="c1">// ...</span>

        <span class="c1">// send a message when a user logs in</span>
        <span class="n">streamBridge</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="s">"produce-out-0"</span><span class="o">,</span> <span class="n">user</span><span class="o">);</span>

        <span class="k">return</span> <span class="s">"Login Successful!"</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>
<p>In this example, each time the “/login” endpoint is hit, a <code class="language-plaintext highlighter-rouge">User</code> object would be sent to the output channel “produce-out-0”.</p>

<p>Remember to configure the output binding in your <code class="language-plaintext highlighter-rouge">application.yml</code> appropriately:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">produce-out-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">topic-name</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">StreamBridge</code> utility provides a flexible way to produce messages from anywhere within your application, making it a great choice when you need to manually send messages in a Spring Cloud Stream application.</p>

<h2 id="what-if-there-are-multiple-functions-but-used-to-be-handle-diff-topics">What if there are multiple functions, but used to be handle diff topics?</h2>

<blockquote>
  <p>What if there are multiple functions, but used to be handle diff topics?</p>
</blockquote>

<p>If you have multiple functions corresponding to different topics (destinations), you can easily configure them in Spring Cloud Stream.</p>

<p>Each <code class="language-plaintext highlighter-rouge">java.util.function.Function</code>, <code class="language-plaintext highlighter-rouge">java.util.function.Consumer</code> or <code class="language-plaintext highlighter-rouge">java.util.function.Supplier</code> bean can correspond to a different binder destination.</p>

<p>Here’s an example:</p>

<p><strong>Producer Function Beans:</strong></p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Supplier</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">produceUserEvent</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// generate user event message content</span>
        <span class="nc">String</span> <span class="n">message</span> <span class="o">=</span> <span class="s">"User event"</span><span class="o">;</span>
        <span class="k">return</span> <span class="n">message</span><span class="o">;</span>
    <span class="o">};</span>
<span class="o">}</span>

<span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Supplier</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">produceProductEvent</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="o">()</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// generate product event message content</span>
        <span class="nc">String</span> <span class="n">message</span> <span class="o">=</span> <span class="s">"Product event"</span><span class="o">;</span>
        <span class="k">return</span> <span class="n">message</span><span class="o">;</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p><strong>Consumer Function Beans:</strong></p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Consumer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">consumeUserEvent</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// process user event message content</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Received user event: "</span> <span class="o">+</span> <span class="n">message</span><span class="o">);</span>
    <span class="o">};</span>
<span class="o">}</span>

<span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Consumer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">consumeProductEvent</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// process product event message content</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Received product event: "</span> <span class="o">+</span> <span class="n">message</span><span class="o">);</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p><strong>Configuration in <code class="language-plaintext highlighter-rouge">application.yml</code>:</strong></p>

<p>You can declare the bindings and specific destinations in your <code class="language-plaintext highlighter-rouge">application.yml</code>:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">produceUserEvent;consumeUserEvent;produceProductEvent;consumeProductEvent</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">produceUserEvent-out-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">user-events</span>
        <span class="na">consumeUserEvent-in-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">user-events</span>
        <span class="na">produceProductEvent-out-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">product-events</span>
        <span class="na">consumeProductEvent-in-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">product-events</span>
      <span class="na">kafka</span><span class="pi">:</span>
        <span class="na">binder</span><span class="pi">:</span>
          <span class="na">brokers</span><span class="pi">:</span> <span class="s">localhost:9092</span>
</code></pre></div></div>

<p>In this example, <code class="language-plaintext highlighter-rouge">produceUserEvent-out-0</code> and <code class="language-plaintext highlighter-rouge">consumeUserEvent-in-0</code> are used to produce and consume messages for “user events”, while <code class="language-plaintext highlighter-rouge">produceProductEvent-out-0</code> and <code class="language-plaintext highlighter-rouge">consumeProductEvent-in-0</code> are used to produce and consume “product events”. Each <code class="language-plaintext highlighter-rouge">-out-0</code> or <code class="language-plaintext highlighter-rouge">-in-0</code> suffix represents the output or input channel binding for that function.</p>

<p>In the end, each function serves its own topic, producing or consuming different set of data, while having separate responsibility.</p>

<blockquote>
  <p>got it, it seems that the function.definition is used to tell the SCS to indentify the handlers?
q</p>
  <ul>
    <li>That’s correct. The <code class="language-plaintext highlighter-rouge">spring.cloud.function.definition</code> property in the application configuration can be used to specify the beans - either <code class="language-plaintext highlighter-rouge">Supplier</code>, <code class="language-plaintext highlighter-rouge">Consumer</code>, or <code class="language-plaintext highlighter-rouge">Function</code> - that Spring Cloud Stream should bind to messaging channels.</li>
  </ul>
</blockquote>

<p>If you have multiple function beans in your Spring application context, but you only want to use some of them for messaging purposes, this is where <code class="language-plaintext highlighter-rouge">spring.cloud.function.definition</code> becomes handy.</p>

<p>The property takes a semi-colon separated list of the bean names to be bound to the messaging system.</p>

<p>For example:</p>
<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">myFunction;myConsumer;mySupplier</span>
</code></pre></div></div>

<p>In this example, <code class="language-plaintext highlighter-rouge">myFunction</code>, <code class="language-plaintext highlighter-rouge">myConsumer</code>, <code class="language-plaintext highlighter-rouge">mySupplier</code> are the names of <code class="language-plaintext highlighter-rouge">Function</code>, <code class="language-plaintext highlighter-rouge">Consumer</code>, <code class="language-plaintext highlighter-rouge">Supplier</code> beans respectively. Spring Cloud Stream will bind only these beans to messaging channels according to the output/input bindings specified elsewhere in your properties.</p>

<p>It’s important to remember that the function definition should have the same name as the function bean in the application. If your function bean is defined as follows:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Consumer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="nf">myConsumer</span><span class="o">()</span> <span class="o">{</span>
  <span class="k">return</span> <span class="n">data</span> <span class="o">-&gt;</span> <span class="o">{</span> <span class="cm">/*...*/</span> <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p>You should use <code class="language-plaintext highlighter-rouge">myConsumer</code> in the <code class="language-plaintext highlighter-rouge">spring.cloud.function.definition</code>.</p>

<h2 id="how-to-compiste-functions-to-handle-a-topic">How to compiste functions to handle a topic?</h2>

<blockquote>
  <p>How to compiste functions to handle a topic?</p>
</blockquote>

<ul>
  <li>Composing functions is a powerful feature of Spring Cloud Stream that allows multiple operations to be performed on a message in a sequence. You can chain multiple functions together to process the input data.</li>
</ul>

<p>To compose functions, you use the pipe symbol <code class="language-plaintext highlighter-rouge">|</code>, similar to how you would in a Unix/Linux command line. Here’s an example:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="nf">firstFunction</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">input</span> <span class="o">-&gt;</span> <span class="n">input</span><span class="o">.</span><span class="na">toUpperCase</span><span class="o">();</span>
<span class="o">}</span>

<span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="nf">secondFunction</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">input</span> <span class="o">-&gt;</span> <span class="s">"Message: "</span> <span class="o">+</span> <span class="n">input</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>And in your application configuration file:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">firstFunction|secondFunction</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">firstFunction</code> will be applied first, and then its output will be used as the input to the <code class="language-plaintext highlighter-rouge">secondFunction</code>. This way, when a message comes in, it’ll be first converted to uppercase by <code class="language-plaintext highlighter-rouge">firstFunction</code>, and then <code class="language-plaintext highlighter-rouge">secondFunction</code> will prepended “Message: “ to it.</p>

<p>Keep in mind, when composing functions:</p>

<ul>
  <li>Each function must “match” with its neighbouring function - the output type of one function should be the same as the input type of the next.</li>
  <li>Create separate Application Configuration file (application.yml or application.properties) for each binder (input or output) when using the composed function. The binding destination should match for both producer and consumer otherwise producer will not be able to send and the consumer won’t consume the messages.</li>
  <li>Composing two or more consumers (<code class="language-plaintext highlighter-rouge">Consumer&lt;A&gt; | Consumer&lt;B&gt;</code>) or two or more suppliers (<code class="language-plaintext highlighter-rouge">Supplier&lt;A&gt; | Supplier&lt;B&gt;</code>) is not valid as per Spring Cloud Stream documentation because the supplier does not consume any input, and the consumer does not produce any output.</li>
  <li>If message types do not match, a converter can be used to typecast them.</li>
</ul>

<h2 id="how-does-the-composite-functions-to-be-bound-to-a-destination">How does the composite functions to be bound to a destination?</h2>

<blockquote>
  <p>How does the composite functions to be bound to a destination?</p>
</blockquote>

<p>The composed (composite) functions can be bound to a destination (topic) through the application configuration file (like application.yml) in Spring Cloud Stream.</p>

<p>The basic procedure is to define the destination in the <code class="language-plaintext highlighter-rouge">spring.cloud.stream.bindings.&lt;functionName&gt;-in-0.destination</code> for input bindings and <code class="language-plaintext highlighter-rouge">spring.cloud.stream.bindings.&lt;functionName&gt;-out-0.destination</code> for output bindings, where <code class="language-plaintext highlighter-rouge">&lt;functionName&gt;</code> is the composed function name.</p>

<p>For example, consider two functions: <code class="language-plaintext highlighter-rouge">uppercase</code> and <code class="language-plaintext highlighter-rouge">prefix</code> which you have composed as <code class="language-plaintext highlighter-rouge">processFunction</code>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="nf">uppercase</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="nl">String:</span><span class="o">:</span><span class="n">toUpperCase</span><span class="o">;</span>
<span class="o">}</span>

<span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="nf">prefix</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">input</span> <span class="o">-&gt;</span> <span class="s">"Hello "</span> <span class="o">+</span> <span class="n">input</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>You define the composite function in your <code class="language-plaintext highlighter-rouge">spring.cloud.function.definition</code> like this:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">processFunction</span>
</code></pre></div></div>

<p>To bind the composite function to a topic, define the input and output bindings:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">processFunction-in-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">input-topic</span>
        <span class="na">processFunction-out-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">output-topic</span>
</code></pre></div></div>

<p>In this setup, messages coming in from <code class="language-plaintext highlighter-rouge">input-topic</code> will trigger the composite function <code class="language-plaintext highlighter-rouge">processFunction</code> (which consists of <code class="language-plaintext highlighter-rouge">uppercase</code> and <code class="language-plaintext highlighter-rouge">prefix</code>) and the results will be sent to <code class="language-plaintext highlighter-rouge">output-topic</code>.</p>

<p>Remember, the <code class="language-plaintext highlighter-rouge">bindings</code> property should match the function name. So if your composed function is called <code class="language-plaintext highlighter-rouge">processFunction</code>, you should have your bindings as <code class="language-plaintext highlighter-rouge">processFunction-in-0</code> and <code class="language-plaintext highlighter-rouge">processFunction-out-0</code>.</p>

<blockquote>
  <p>I didn’t see any configuration about the realtion between processFunction and the uppercase and prefix.</p>
</blockquote>

<table>
  <tbody>
    <tr>
      <td>I apologize for the confusion, I should have clarified that in the explanation. The processFunction was intended as a placeholder name in the bindings configuration for the composed function (uppercase</td>
      <td>prefix).</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>The binding happens based on the <code class="language-plaintext highlighter-rouge">spring.cloud.function.definition</code> property. The composed function is defined as the concatenation of the beans you want to compose (uppercase</td>
      <td>prefix, in this case) in the <code class="language-plaintext highlighter-rouge">spring.cloud.function.definition</code> property.</td>
    </tr>
  </tbody>
</table>

<p>Here’s how you can specify <code class="language-plaintext highlighter-rouge">uppercase</code> and <code class="language-plaintext highlighter-rouge">prefix</code> functions and bind them to input and output channels:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="nf">uppercase</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="nl">String:</span><span class="o">:</span><span class="n">toUpperCase</span><span class="o">;</span>
<span class="o">}</span>

<span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">Function</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="nf">prefix</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">input</span> <span class="o">-&gt;</span> <span class="s">"Hello "</span> <span class="o">+</span> <span class="n">input</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>In your <code class="language-plaintext highlighter-rouge">application.yml</code>, you compose them together:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">function</span><span class="pi">:</span>
      <span class="na">definition</span><span class="pi">:</span> <span class="s">uppercase|prefix</span>
  <span class="na">cloud</span><span class="pi">:</span>
    <span class="na">stream</span><span class="pi">:</span>
      <span class="na">bindings</span><span class="pi">:</span>
        <span class="na">uppercase|prefix-in-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">input-topic</span>
        <span class="na">uppercase|prefix-out-0</span><span class="pi">:</span>
          <span class="na">destination</span><span class="pi">:</span> <span class="s">output-topic</span>
</code></pre></div></div>
<p>In this setup, when a message comes in from the <code class="language-plaintext highlighter-rouge">input-topic</code>, it is first processed by the <code class="language-plaintext highlighter-rouge">uppercase</code> function, and then it’s output is processed by the <code class="language-plaintext highlighter-rouge">prefix</code> function, and then the final output is sent to <code class="language-plaintext highlighter-rouge">output-topic</code>.</p>

<p>The use of <code class="language-plaintext highlighter-rouge">|</code> (pipe) character enables function composition, where the output of one function becomes the input of the next one in line.</p>

<style>
  .utterances {
      max-width: 100%;
  }
</style>
<script src="https://utteranc.es/client.js"
        repo="looogos/utterances"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

</div>
</article>
    </main>
    <footer class="c-footer">
  <div class="c-footer-license">
    <span>Article licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></span>
  </div>
  
  <details class="c-footer-extralinks" open>
    <summary class="c-footer-extralinks-summary">Extral Links</summary>
    <div class="c-footer-extralinks-content">
      
      <a href="https://jekyllrb.com/">Jekyll</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://shopify.github.io/liquid/">Liquid</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://docs.asciidoctor.org/">Asciidoctor</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://github.com/qqbuby/">GitHub</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="/feed.xml">RSS</a>
      
      
    </div>
  </details>
  
</footer>

    <script src="/assets/js/nav.js" defer></script>
    <script src="/assets/js/heading-anchors.js" defer></script>
    <!-- https://cdn.jsdelivr.net/gh/lurongkai/anti-baidu/js/anti-baidu-latest.min.js -->    
    <script type="text/javascript" src="/js/anti-baidu.min.js" charset="UTF-8"></script>
  </body>
</html>
